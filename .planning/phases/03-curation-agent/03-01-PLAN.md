---
phase: 03-curation-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/editorial_ai/models/curation.py
  - src/editorial_ai/prompts/curation.py
  - src/editorial_ai/services/curation_service.py
  - tests/test_curation_service.py
autonomous: true

must_haves:
  truths:
    - "CurationService takes a seed keyword and returns structured CuratedTopic list"
    - "Two-step Gemini pattern: grounded research call then structured JSON extraction call"
    - "API failures are retried with exponential backoff (3 attempts, tenacity)"
    - "Empty/poor grounding metadata produces results with low_quality=true flag"
    - "Topics below relevance_score 0.6 are filtered out"
    - "Grounding source URLs are extracted from response metadata"
  artifacts:
    - path: "src/editorial_ai/models/curation.py"
      provides: "CuratedTopic, CelebReference, BrandReference, GroundingSource, CurationResult Pydantic models"
      exports: ["CuratedTopic", "CelebReference", "BrandReference", "GroundingSource", "CurationResult"]
    - path: "src/editorial_ai/prompts/curation.py"
      provides: "Prompt templates for trend research and JSON extraction"
      exports: ["build_trend_research_prompt", "build_extraction_prompt", "build_subtopic_expansion_prompt"]
    - path: "src/editorial_ai/services/curation_service.py"
      provides: "CurationService class with research_trend, expand_subtopics, curate_topic, curate_seed methods"
      exports: ["CurationService", "get_genai_client"]
    - path: "tests/test_curation_service.py"
      provides: "Unit tests with mocked Gemini responses"
  key_links:
    - from: "src/editorial_ai/services/curation_service.py"
      to: "src/editorial_ai/models/curation.py"
      via: "Pydantic model_validate_json for response parsing"
      pattern: "CuratedTopic\\.model_validate"
    - from: "src/editorial_ai/services/curation_service.py"
      to: "google.genai"
      via: "Native google-genai SDK async client (client.aio.models.generate_content)"
      pattern: "client\\.aio\\.models\\.generate_content"
    - from: "src/editorial_ai/services/curation_service.py"
      to: "tenacity"
      via: "Retry decorator on API calls"
      pattern: "@retry"
---

<objective>
Curation service layer: Pydantic models for curated topic output, prompt templates, and CurationService class that uses Gemini + Google Search Grounding with the two-step pattern (grounded research → structured extraction).

Purpose: Encapsulate all Gemini grounding API interaction in a testable service class. The LangGraph node (Plan 03-02) will call this service and write results to pipeline state.

Output: Working CurationService with Pydantic models, prompt templates, retry logic, and unit tests proving the two-step pipeline works correctly with mocked responses.
</objective>

<execution_context>
@/Users/kiyeol/.claude-pers/get-shit-done/workflows/execute-plan.md
@/Users/kiyeol/.claude-pers/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-curation-agent/03-CONTEXT.md
@.planning/phases/03-curation-agent/03-RESEARCH.md
@src/editorial_ai/config.py
@src/editorial_ai/state.py
@src/editorial_ai/llm.py
@src/editorial_ai/models/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Curation Pydantic models and prompt templates</name>
  <files>
    src/editorial_ai/models/curation.py
    src/editorial_ai/prompts/__init__.py
    src/editorial_ai/prompts/curation.py
  </files>
  <action>
Create Pydantic models in `src/editorial_ai/models/curation.py`:

```python
class CelebReference(BaseModel):
    name: str
    relevance: str

class BrandReference(BaseModel):
    name: str
    relevance: str

class GroundingSource(BaseModel):
    url: str
    title: str | None = None

class CuratedTopic(BaseModel):
    keyword: str
    trend_background: str
    related_keywords: list[str]
    celebrities: list[CelebReference]
    brands_products: list[BrandReference]
    seasonality: str
    sources: list[GroundingSource] = Field(default_factory=list)
    relevance_score: float = Field(ge=0.0, le=1.0, description="0-1 trend relevance score")
    low_quality: bool = False

class CurationResult(BaseModel):
    seed_keyword: str
    topics: list[CuratedTopic]
    total_generated: int  # before filtering
    total_filtered: int   # after relevance threshold
```

Use Python 3.12+ union syntax (`str | None`). Follow project convention from existing models (`src/editorial_ai/models/celeb.py`).

Create prompt templates in `src/editorial_ai/prompts/curation.py`:

1. `build_trend_research_prompt(keyword: str) -> str` — Prompt for grounded Gemini call. Ask for fashion trend background, sub-topics, related keywords, celebrities, brands, seasonality. Language: Korean + English mix. Instruct Gemini to be comprehensive and use search grounding.

2. `build_subtopic_expansion_prompt(keyword: str, trend_background: str) -> str` — Prompt to extract 3-7 sub-topic keyword strings from the initial research. Return as JSON array of strings.

3. `build_extraction_prompt(keyword: str, raw_research: str) -> str` — Prompt for structured JSON extraction from grounded research text. Define the exact JSON schema matching CuratedTopic fields including relevance_score (0-1). Instruct the model to output ONLY valid JSON.

Create empty `src/editorial_ai/prompts/__init__.py`.

Update `src/editorial_ai/models/__init__.py` to re-export curation models.
  </action>
  <verify>
Run: `cd /Users/kiyeol/development/decoded/editorial-ai-worker && uv run python -c "from editorial_ai.models.curation import CuratedTopic, CurationResult; from editorial_ai.prompts.curation import build_trend_research_prompt, build_extraction_prompt, build_subtopic_expansion_prompt; print('OK')"`
  </verify>
  <done>
CuratedTopic and related models importable. Three prompt builder functions importable and return non-empty strings when called with test inputs.
  </done>
</task>

<task type="auto">
  <name>Task 2: CurationService with two-step Gemini grounding</name>
  <files>
    src/editorial_ai/services/curation_service.py
  </files>
  <action>
Create `CurationService` class using the native `google-genai` SDK (NOT langchain-google-genai). This is a LOCKED decision from RESEARCH.md — the native SDK provides cleaner grounding metadata access.

**`get_genai_client() -> genai.Client`** factory function:
- Create `genai.Client(api_key=settings.google_api_key)`
- If `settings.google_api_key` is None, raise `ValueError("GOOGLE_API_KEY required for curation service")`

**`CurationService.__init__(self, client: genai.Client, *, model: str | None = None, relevance_threshold: float = 0.6)`**
- Store client, model (default from settings.default_model), and relevance_threshold

**Retry decorator** using tenacity:
```python
retry_on_api_error = retry(
    retry=retry_if_exception_type((ClientError, ServerError)),
    wait=wait_exponential(multiplier=1, min=1, max=60),
    stop=stop_after_attempt(3),
    reraise=True,
)
```

**`async def research_trend(self, keyword: str) -> tuple[str, list[GroundingSource]]`**:
- Step 1 of two-step pattern: Grounded Gemini call
- Call `self.client.aio.models.generate_content()` with:
  - model=self.model
  - contents=build_trend_research_prompt(keyword)
  - config: tools=[types.Tool(google_search=types.GoogleSearch())], temperature=0.7
- Extract grounding sources from `response.candidates[0].grounding_metadata.grounding_chunks` (with None checks at each level)
- If grounding_metadata is None or grounding_chunks is empty, return empty sources list
- Return (response.text, sources)
- Decorated with retry_on_api_error

**`async def expand_subtopics(self, keyword: str, trend_background: str) -> list[str]`**:
- Grounded call with build_subtopic_expansion_prompt
- Use response_mime_type="application/json" (no grounding needed for this step)
- Parse JSON array of strings, cap at 7 sub-topics
- Decorated with retry_on_api_error

**`async def extract_topic(self, keyword: str, raw_research: str, sources: list[GroundingSource]) -> CuratedTopic`**:
- Step 2 of two-step pattern: Structured extraction (no grounding)
- Call generate_content with:
  - contents=build_extraction_prompt(keyword, raw_research)
  - config: response_mime_type="application/json", temperature=0.0
- Parse with `CuratedTopic.model_validate_json(response.text)`
- Fallback: strip markdown code fences (```json ... ```) before parsing
- Attach sources to the validated topic (override sources field)
- If Pydantic validation fails, log warning and return topic with low_quality=True and reasonable defaults
- Decorated with retry_on_api_error

**`async def curate_topic(self, keyword: str) -> CuratedTopic | None`**:
- Full pipeline for one topic: research_trend → extract_topic
- If extraction fails completely, return None

**`async def curate_seed(self, seed_keyword: str) -> CurationResult`**:
- Entry point called by the LangGraph node
- 1. Call research_trend(seed_keyword) for initial background
- 2. Call expand_subtopics(seed_keyword, background) to get sub-topic keywords
- 3. Include seed_keyword itself as first topic
- 4. For each keyword (seed + sub-topics), call curate_topic() sequentially (not parallel — avoid rate limits per RESEARCH.md pitfall 4)
- 5. Filter out None results and topics with relevance_score < self.relevance_threshold
- 6. Return CurationResult with seed_keyword, filtered topics, counts

**Error handling:**
- If all retries exhaust for research_trend on the seed keyword, raise (propagate to node for pipeline failure)
- If a sub-topic's curate_topic fails, skip that sub-topic (don't fail entire curation)
- If grounding results are empty/poor, still produce topic with low_quality=True
  </action>
  <verify>
Run: `cd /Users/kiyeol/development/decoded/editorial-ai-worker && uv run python -c "from editorial_ai.services.curation_service import CurationService, get_genai_client; print('OK')"`

Run: `cd /Users/kiyeol/development/decoded/editorial-ai-worker && uv run mypy src/editorial_ai/services/curation_service.py --ignore-missing-imports`
  </verify>
  <done>
CurationService class importable with all methods defined. mypy reports no errors. Two-step pattern implemented: research_trend (grounded) → extract_topic (structured JSON). Retry decorator applied to all API-calling methods.
  </done>
</task>

<task type="auto">
  <name>Task 3: CurationService unit tests with mocked Gemini responses</name>
  <files>
    tests/test_curation_service.py
  </files>
  <action>
Create comprehensive unit tests for CurationService with mocked Gemini API responses. Follow project test conventions from `tests/test_services.py` (MagicMock for sync, AsyncMock for async).

**Test fixtures:**
- `mock_genai_client`: MagicMock with `aio.models.generate_content` as AsyncMock
- `sample_grounded_response`: Mock response object with:
  - `.text` = realistic Korean+English fashion trend text
  - `.candidates[0].grounding_metadata.grounding_chunks` = list of mock chunks with `.web.uri` and `.web.title`
- `sample_extraction_response`: Mock response with `.text` = valid JSON matching CuratedTopic schema
- `sample_subtopic_response`: Mock response with `.text` = JSON array of 5 sub-topic strings

**Test cases:**

1. `test_research_trend_returns_text_and_sources` — Verify research_trend returns (text, sources) tuple with correct source extraction from grounding metadata.

2. `test_research_trend_empty_grounding` — When grounding_metadata is None, returns empty sources list (not error).

3. `test_expand_subtopics_returns_capped_list` — Verify subtopics are parsed from JSON and capped at 7.

4. `test_extract_topic_valid_json` — Verify CuratedTopic is correctly parsed from mock JSON response.

5. `test_extract_topic_markdown_fence_fallback` — When response.text has ```json fences, they are stripped and parsing succeeds.

6. `test_curate_seed_end_to_end` — Full pipeline: mock all three API calls, verify CurationResult has correct seed_keyword, filtered topics (above threshold), and counts.

7. `test_curate_seed_filters_low_relevance` — Topics with relevance_score < 0.6 are excluded from final result.

8. `test_curate_seed_skips_failed_subtopic` — When one sub-topic's curate_topic raises, it's skipped and other topics still returned.

9. `test_retry_on_api_error` — When first API call raises ClientError, tenacity retries and succeeds on second attempt.

All tests should be async (use `@pytest.mark.asyncio` with project's pytest-asyncio config).

Mock the `generate_content` method using side_effect to return different responses for different calls (research, subtopic expansion, extraction calls are made sequentially).
  </action>
  <verify>
Run: `cd /Users/kiyeol/development/decoded/editorial-ai-worker && uv run pytest tests/test_curation_service.py -v`

All tests pass. No test requires real API credentials.
  </verify>
  <done>
9+ tests pass covering: two-step pattern, source extraction, empty grounding handling, relevance filtering, sub-topic failure resilience, retry behavior. All tests use mocked Gemini responses with no real API calls.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from editorial_ai.models.curation import CuratedTopic, CurationResult; print('Models OK')"` — Models importable
2. `uv run python -c "from editorial_ai.services.curation_service import CurationService; print('Service OK')"` — Service importable
3. `uv run pytest tests/test_curation_service.py -v` — All tests pass
4. `uv run mypy src/editorial_ai/models/curation.py src/editorial_ai/services/curation_service.py --ignore-missing-imports` — No type errors
5. `uv run ruff check src/editorial_ai/models/curation.py src/editorial_ai/services/curation_service.py src/editorial_ai/prompts/curation.py` — No lint errors
</verification>

<success_criteria>
- CurationService.curate_seed() takes a keyword string and returns CurationResult with structured CuratedTopic list
- Two-step Gemini pattern proven: grounded call → structured extraction call (verified by tests)
- Retry logic wraps all API calls (tested with mock ClientError)
- Empty grounding handled gracefully with low_quality flag
- Relevance threshold filtering works (configurable, default 0.6)
- All unit tests pass with mocked responses (no real API needed)
</success_criteria>

<output>
After completion, create `.planning/phases/03-curation-agent/03-01-SUMMARY.md`
</output>
