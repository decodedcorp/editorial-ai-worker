---
phase: 02-data-layer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/editorial_ai/config.py
  - src/editorial_ai/services/__init__.py
  - src/editorial_ai/services/supabase_client.py
  - src/editorial_ai/services/celeb_service.py
  - src/editorial_ai/services/product_service.py
  - src/editorial_ai/services/post_service.py
  - src/editorial_ai/models/__init__.py
  - src/editorial_ai/models/celeb.py
  - src/editorial_ai/models/product.py
  - src/editorial_ai/models/post.py
  - tests/test_services.py
autonomous: true
user_setup:
  - service: supabase
    why: "Supabase REST API + Postgres pooler access for data reads and checkpointer"
    env_vars:
      - name: SUPABASE_URL
        source: "Supabase Dashboard -> Settings -> API -> Project URL"
      - name: SUPABASE_SERVICE_ROLE_KEY
        source: "Supabase Dashboard -> Settings -> API -> service_role key (secret)"
      - name: DATABASE_URL
        source: "Supabase Dashboard -> Settings -> Database -> Connection string -> Session mode (port 5432). Format: postgres://postgres.[project-ref]:[password]@aws-0-[region].pooler.supabase.com:5432/postgres"

must_haves:
  truths:
    - "Supabase async client can be created with service_role key and returns a valid AsyncClient"
    - "Service functions can query celebs/products/posts from Supabase by ID and by text search"
    - "Service layer returns typed Pydantic models, not raw dicts"
    - "Service layer tests pass with mocked Supabase client (no live DB required for CI)"
  artifacts:
    - path: "src/editorial_ai/config.py"
      provides: "Settings with SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, DATABASE_URL"
      contains: "supabase_url"
    - path: "src/editorial_ai/services/supabase_client.py"
      provides: "Singleton async client factory"
      exports: ["get_supabase_client"]
    - path: "src/editorial_ai/services/celeb_service.py"
      provides: "Celeb read operations"
      exports: ["get_celeb_by_id", "search_celebs"]
    - path: "src/editorial_ai/services/product_service.py"
      provides: "Product read operations"
      exports: ["get_product_by_id", "search_products"]
    - path: "src/editorial_ai/services/post_service.py"
      provides: "Post read operations"
      exports: ["get_post_by_id", "list_posts"]
    - path: "src/editorial_ai/models/celeb.py"
      provides: "Celeb Pydantic model"
      exports: ["Celeb"]
    - path: "src/editorial_ai/models/product.py"
      provides: "Product Pydantic model"
      exports: ["Product"]
    - path: "src/editorial_ai/models/post.py"
      provides: "Post Pydantic model"
      exports: ["Post"]
  key_links:
    - from: "src/editorial_ai/services/supabase_client.py"
      to: "src/editorial_ai/config.py"
      via: "settings.supabase_url, settings.supabase_service_role_key"
      pattern: "settings\\.supabase_"
    - from: "src/editorial_ai/services/celeb_service.py"
      to: "src/editorial_ai/services/supabase_client.py"
      via: "get_supabase_client()"
      pattern: "get_supabase_client"
    - from: "src/editorial_ai/services/celeb_service.py"
      to: "src/editorial_ai/models/celeb.py"
      via: "returns Celeb model instances"
      pattern: "Celeb\\("
---

<objective>
Supabase 서비스 레이어를 구축한다: 설정 확장, 의존성 설치, async 클라이언트 팩토리, Pydantic 모델, 셀럽/상품/포스트 Read-only 서비스 함수, 단위 테스트.

Purpose: 파이프라인 노드들이 Supabase에서 셀럽/상품/포스트 데이터를 조회할 수 있는 서비스 레이어를 제공한다. Phase 5 (DB Tools)에서 이 서비스 레이어를 LangChain Tool로 바인딩하여 Editorial Agent가 사용하게 된다.

Output: `src/editorial_ai/services/` 및 `src/editorial_ai/models/` 디렉토리 아래에 Supabase 서비스 레이어와 Pydantic 모델이 생성되고, 단위 테스트가 통과한다.
</objective>

<execution_context>
@/Users/kiyeol/.claude-pers/get-shit-done/workflows/execute-plan.md
@/Users/kiyeol/.claude-pers/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-layer/02-CONTEXT.md
@.planning/phases/02-data-layer/02-RESEARCH.md
@src/editorial_ai/config.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies, extend config, create Supabase client factory</name>
  <files>
    pyproject.toml
    src/editorial_ai/config.py
    src/editorial_ai/services/__init__.py
    src/editorial_ai/services/supabase_client.py
  </files>
  <action>
1. Install dependencies:
   ```bash
   uv add supabase langgraph-checkpoint-postgres "psycopg[binary]"
   ```
   This adds all Phase 2 deps at once (supabase for service layer, checkpoint-postgres + psycopg for Plan 02-02).

2. Extend `src/editorial_ai/config.py` Settings class with three new fields:
   ```python
   # Supabase (REST API)
   supabase_url: str | None = Field(default=None, alias="SUPABASE_URL")
   supabase_service_role_key: str | None = Field(default=None, alias="SUPABASE_SERVICE_ROLE_KEY")

   # Postgres (for checkpointer — Supabase session pooler, port 5432)
   database_url: str | None = Field(default=None, alias="DATABASE_URL")
   ```
   Use `str | None` with default=None (same pattern as google_api_key) so the app doesn't crash when env vars are missing — they're only needed when actually connecting to Supabase.

3. Create `src/editorial_ai/services/__init__.py` (empty, or re-export key functions).

4. Create `src/editorial_ai/services/supabase_client.py`:
   - Singleton async client factory using `acreate_client` from `supabase`.
   - Use module-level `_client: AsyncClient | None = None` for lazy initialization.
   - `get_supabase_client()` async function that creates client on first call, returns cached client on subsequent calls.
   - Raise a clear error if `settings.supabase_url` or `settings.supabase_service_role_key` is None.
   - Follow existing code style (docstrings, type hints, Python 3.12+ syntax).

5. Verify: `uv run python -c "from editorial_ai.services.supabase_client import get_supabase_client; print('OK')"` succeeds (import check only, no actual connection).

6. Run `uv run ruff check src/editorial_ai/` and `uv run mypy src/editorial_ai/` to check lint/types.
  </action>
  <verify>
    - `uv run python -c "from editorial_ai.config import settings; print(settings.supabase_url)"` prints None (no .env configured)
    - `uv run python -c "from editorial_ai.services.supabase_client import get_supabase_client; print('import OK')"` succeeds
    - `uv run ruff check src/editorial_ai/` passes
    - mypy passes (or only has pre-existing issues)
  </verify>
  <done>
    - pyproject.toml includes supabase, langgraph-checkpoint-postgres, psycopg[binary] dependencies
    - Settings has supabase_url, supabase_service_role_key, database_url fields (all optional with None default)
    - Supabase client factory module exists with get_supabase_client async function
    - All imports resolve, lint passes
  </done>
</task>

<task type="auto">
  <name>Task 2: Discover Supabase schemas, create Pydantic models, service functions, and tests</name>
  <files>
    src/editorial_ai/models/__init__.py
    src/editorial_ai/models/celeb.py
    src/editorial_ai/models/product.py
    src/editorial_ai/models/post.py
    src/editorial_ai/services/celeb_service.py
    src/editorial_ai/services/product_service.py
    src/editorial_ai/services/post_service.py
    tests/test_services.py
  </files>
  <action>
**IMPORTANT: Schema Discovery Step**

Before creating Pydantic models, you MUST discover the actual Supabase table schemas. The celeb/product/post tables already exist in Supabase. The user has set SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY in .env.local (check .env or .env.local).

Run a quick schema inspection script:
```python
import asyncio
from supabase import acreate_client

async def inspect():
    client = await acreate_client(url, key)
    # Fetch one row from each table to see column names and types
    for table in ["celebs", "products", "posts"]:
        try:
            resp = client.table(table).select("*").limit(1).execute()
            print(f"\n=== {table} ===")
            if resp.data:
                print(list(resp.data[0].keys()))
            else:
                print("(empty table)")
        except Exception as e:
            print(f"{table}: {e}")
asyncio.run(inspect())
```

Note: Table names might differ (e.g., "celeb" vs "celebs", "product" vs "products"). Try variations if the first attempt fails. If a table doesn't exist, create the model with reasonable defaults (id, name, created_at) and add a comment noting it needs schema verification.

**After discovering schemas:**

1. Create `src/editorial_ai/models/__init__.py` — re-export Celeb, Product, Post.

2. Create Pydantic models in `src/editorial_ai/models/`:
   - `celeb.py`: `Celeb(BaseModel)` matching the actual Supabase schema. Use `str | None` for nullable columns. Include `model_config = ConfigDict(from_attributes=True)` for ORM compatibility.
   - `product.py`: `Product(BaseModel)` same pattern.
   - `post.py`: `Post(BaseModel)` same pattern.

3. Create service functions in `src/editorial_ai/services/`:

   `celeb_service.py`:
   - `async def get_celeb_by_id(celeb_id: str) -> Celeb | None` — uses `.eq("id", celeb_id).maybe_single().execute()`
   - `async def search_celebs(query: str, *, limit: int = 10) -> list[Celeb]` — uses `.ilike("name", f"%{query}%").limit(limit).execute()`
   - Both use `await get_supabase_client()` then call PostgREST methods.
   - Note: supabase-py async client methods (table, select, eq, ilike, etc.) are synchronous builders, only `execute()` is the actual call. For async client, the query builder returns response directly without needing `await` on execute. Check actual API behavior during implementation.

   `product_service.py`:
   - `async def get_product_by_id(product_id: str) -> Product | None`
   - `async def search_products(query: str, *, limit: int = 10) -> list[Product]`
   - Same pattern as celeb_service.

   `post_service.py`:
   - `async def get_post_by_id(post_id: str) -> Post | None`
   - `async def list_posts(*, limit: int = 20) -> list[Post]` — returns recent posts, ordered by created_at desc if available.

4. Create `tests/test_services.py`:
   - **Unit tests with mocked Supabase client** (NOT integration tests against live Supabase).
   - Mock `get_supabase_client` to return a mock AsyncClient.
   - Mock the PostgREST query chain (table -> select -> eq -> execute pattern).
   - Test cases:
     - `test_get_celeb_by_id_found` — returns Celeb when data exists
     - `test_get_celeb_by_id_not_found` — returns None when no data
     - `test_search_celebs_returns_list` — returns list[Celeb]
     - `test_search_celebs_empty` — returns empty list
     - Same pattern for product and post services (at least 2 tests each)
   - Use `pytest.mark.asyncio` (or rely on asyncio_mode=auto from pyproject.toml).
   - Use `unittest.mock.AsyncMock` and `patch` for mocking.

   Additionally, add integration test stubs marked with `@pytest.mark.integration` that can be run manually against real Supabase:
   ```python
   @pytest.mark.integration
   async def test_search_celebs_integration():
       """Read-only test against real Supabase. Run manually with: uv run pytest -m integration"""
       results = await search_celebs("김", limit=5)
       assert isinstance(results, list)
   ```

   Add to `pyproject.toml` under `[tool.pytest.ini_options]`:
   ```
   markers = ["integration: marks tests as integration tests (deselect with '-m \"not integration\"')"]
   ```
   And set default: `addopts = "-m 'not integration'"` so integration tests don't run by default.

5. Run `uv run pytest tests/test_services.py -v` to verify all unit tests pass.
6. Run `uv run ruff check src/ tests/` and `uv run mypy src/editorial_ai/` to verify lint/types.
  </action>
  <verify>
    - `uv run pytest tests/test_services.py -v` — all unit tests pass (mocked, no live Supabase needed)
    - `uv run pytest tests/ -v` — all existing + new tests pass
    - `uv run ruff check src/ tests/` — no lint errors
    - `uv run python -c "from editorial_ai.models import Celeb, Product, Post; print('models OK')"` — imports work
    - `uv run python -c "from editorial_ai.services.celeb_service import get_celeb_by_id, search_celebs; print('services OK')"` — imports work
  </verify>
  <done>
    - Pydantic models (Celeb, Product, Post) match actual Supabase table schemas
    - Service functions (get_by_id, search/list) exist for all three entities
    - Unit tests with mocked Supabase client pass in CI (no live DB dependency)
    - Integration test stubs exist with @pytest.mark.integration marker
    - All lint and type checks pass
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/ -v` — all tests pass (unit tests only, integration excluded by default)
2. `uv run ruff check src/ tests/` — clean
3. `uv run mypy src/editorial_ai/` — clean (or pre-existing issues only)
4. Import chain works: `from editorial_ai.services.celeb_service import search_celebs` resolves
5. Config loads without errors when env vars are absent (optional fields)
</verification>

<success_criteria>
- Settings class has supabase_url, supabase_service_role_key, database_url (all optional)
- Supabase async client factory creates client with service_role key
- 3 Pydantic models match actual Supabase schemas
- 6 service functions (2 per entity: get_by_id + search/list)
- Unit tests pass with mocked client, no live Supabase dependency for CI
- Integration test markers configured for manual Supabase verification
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-layer/02-01-SUMMARY.md`
</output>
